{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c6624b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Normative Modeling of ABCD Data (Thickness_SubcorticalVolume) using Rutherford Normed Data ##\n",
    "\n",
    "# The purpose of this script is to essentially concatenate all ABCD data with relevant information, and then apply the pretrained \n",
    "# models from Rutherford (2022, 2023 at eLife) to derive normative estimates for each participant. All of the datasets were used in the\n",
    "# training dataset, so while the \"adaptation\" code is included, it is irrelevant here.\n",
    "# This is the version of the code used to derive data for a manuscript submission we had. The only \"cleaning\"\n",
    "# Is to remove specific pathways that are specific to our lab. This is removed with a generic \"[Path].\" Some other\n",
    "# commented out sections are included as there was troubleshooting but may need to be uncommented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c07da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set working and braincharts directory location\n",
    "import os\n",
    "WorkingDir = '/[Path]/BLR_Rutherford'\n",
    "os.chdir(WorkingDir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca4ad80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clone The GitHub Directory if we haven't already\n",
    "#! git clone https://github.com/predictive-clinical-neuroscience/braincharts.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e96a42",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Activate the correct environment and import the toolkit\n",
    "BrainChartsDir = os.path.join(WorkingDir,'braincharts')\n",
    "os.chdir(BrainChartsDir)\n",
    "os.chdir('scripts')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import pcntoolkit as pcn\n",
    "from pcntoolkit.normative import estimate, predict, evaluate\n",
    "from pcntoolkit.util.utils import compute_MSLL, create_design_matrix\n",
    "from nm_utils import remove_bad_subjects, load_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd3bae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move to the data location\n",
    "os.chdir('/[Path]/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e352c193",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load ABCD Aparc and Aseg FilesSub Names with NDAR SubjectKey\n",
    "os.chdir('/[Path]/ABCD_Data')\n",
    "ABCD_Dem=pd.read_csv(\"pdem02.txt\", sep=\"\\t\", skiprows=[1])\n",
    "ABCD_LongDem=pd.read_csv(\"abcd_lpds01.txt\", sep=\"\\t\", skiprows=[1])\n",
    "ABCD_Aparc=pd.read_csv(\"abcd_mrisdp10201.txt\", sep=\"\\t\", skiprows=[1])\n",
    "ABCD_Aseg = pd.read_csv(\"abcd_smrip10201.txt\", sep=\"\\t\", skiprows=[1])\n",
    "ABCD_Site = pd.read_csv(\"abcd_lt01.txt\", sep=\"\\t\", skiprows=[1])\n",
    "ABCD_Res = pd.read_csv(\"abcd_rhds01.txt\", sep=\"\\t\", skiprows=[1])\n",
    "\n",
    "\n",
    "#HCP_A_LH_Aparc=pd.read_csv(\"HCP_Aging_Destrieux_Thickness_LH.txt\", sep=\"\\t\")\n",
    "#HCP_A_LH_Aparc['src_subject_id']=HCP_A_LH_Aparc['lh.aparc.a2009s.thickness'].str.split('_').str[0]\n",
    "#HCP_A_MRNames = HCP_A_LH_Aparc.pop('src_subject_id')\n",
    "#HCP_A_LH_Aparc.insert(0, 'src_subject_id', HCP_A_MRNames)\n",
    "#HCP_A_RH_Aparc=pd.read_csv(\"HCP_Aging_Destrieux_Thickness_RH.txt\", sep=\"\\t\")\n",
    "#HCP_A_RH_Aparc.insert(0, 'src_subject_id', HCP_A_MRNames)\n",
    "#HCP_A_Aseg=pd.read_csv(\"HCP_Aging_AsegStats.txt\", sep=\"\\t\")\n",
    "#HCP_A_Aseg_Names=pd.read_csv(\"SubsFullFile.txt\", sep=\"\\t\", header=None)\n",
    "#HCP_A_Aseg_Names['src_subject_id']=HCP_A_Aseg_Names[0].str.split('_').str[0]\n",
    "#HCP_A_ASeg_SubName=HCP_A_Aseg_Names.pop('src_subject_id')\n",
    "#HCP_A_Aseg.insert(0, 'src_subject_id', HCP_A_ASeg_SubName)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8efd2f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get specific variables for concatenation\n",
    "ABCD_ResVars = ABCD_Res[['subjectkey', 'eventname', 'reshist_addr1_adi_perc', 'reshist_addr1_no2', 'reshist_addr1_pm25', 'reshist_state_racism_factor', 'reshist_addr1_coi_r_coi_nat']].copy()\n",
    "ABCD_SiteVars = ABCD_Site[['subjectkey', 'eventname', 'site_id_l']].copy()\n",
    "ABCD_DemVars = ABCD_Dem[['subjectkey', 'eventname', 'interview_age', 'sex', 'demo_comb_income_v2', 'demo_prnt_ed_v2', 'demo_prtnr_ed_v2', 'demo_prnt_empl_v2', 'demo_prtnr_empl_v2', 'demo_prnt_marital_v2', 'demo_race_a_p___10', 'demo_race_a_p___11', 'demo_race_a_p___12', 'demo_race_a_p___13', 'demo_race_a_p___14', 'demo_race_a_p___15', 'demo_race_a_p___16', 'demo_race_a_p___17', 'demo_race_a_p___18', 'demo_race_a_p___19', 'demo_race_a_p___20', 'demo_race_a_p___21', 'demo_race_a_p___22', 'demo_race_a_p___23', 'demo_race_a_p___24', 'demo_race_a_p___25', 'demo_race_a_p___77', 'demo_race_a_p___99', ]].copy()\n",
    "ABCD_LongDemVars = ABCD_LongDem[['subjectkey', 'eventname', 'interview_age', 'sex', 'demo_comb_income_v2_l', 'demo_prnt_ed_v2_2yr_l', 'demo_prtnr_ed_v2_2yr_l', 'demo_prnt_empl_v2_l', 'demo_prtnr_empl_v2_l', 'demo_prnt_marital_v2_l']].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa439c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Aparc and Aseg Names #\n",
    "Aparc_Dict = {'mrisdp_1' : 'lh_G&S_frontomargin_thickness',\n",
    "'mrisdp_2' : 'lh_G&S_occipital_inf_thickness',\n",
    "'mrisdp_3' : 'lh_G&S_paracentral_thickness',\n",
    "'mrisdp_4' : 'lh_G&S_subcentral_thickness',\n",
    "'mrisdp_5' : 'lh_G&S_transv_frontopol_thickness',\n",
    "'mrisdp_6' : 'lh_G&S_cingul-Ant_thickness',\n",
    "'mrisdp_7' : 'lh_G&S_cingul-Mid-Ant_thickness',\n",
    "'mrisdp_8' : 'lh_G&S_cingul-Mid-Post_thickness',\n",
    "'mrisdp_9' : 'lh_G_cingul-Post-dorsal_thickness',\n",
    "'mrisdp_10' : 'lh_G_cingul-Post-ventral_thickness',\n",
    "'mrisdp_11' : 'lh_G_cuneus_thickness',\n",
    "'mrisdp_12' : 'lh_G_front_inf-Opercular_thickness',\n",
    "'mrisdp_13' : 'lh_G_front_inf-Orbital_thickness',\n",
    "'mrisdp_14' : 'lh_G_front_inf-Triangul_thickness',\n",
    "'mrisdp_15' : 'lh_G_front_middle_thickness',\n",
    "'mrisdp_16' : 'lh_G_front_sup_thickness',\n",
    "'mrisdp_17' : 'lh_G_Ins_lg&S_cent_ins_thickness',\n",
    "'mrisdp_18' : 'lh_G_insular_short_thickness',\n",
    "'mrisdp_19' : 'lh_G_occipital_middle_thickness',\n",
    "'mrisdp_20' : 'lh_G_occipital_sup_thickness',\n",
    "'mrisdp_21' : 'lh_G_oc-temp_lat-fusifor_thickness',\n",
    "'mrisdp_22' : 'lh_G_oc-temp_med-Lingual_thickness',\n",
    "'mrisdp_23' : 'lh_G_oc-temp_med-Parahip_thickness',\n",
    "'mrisdp_24' : 'lh_G_orbital_thickness',\n",
    "'mrisdp_25' : 'lh_G_pariet_inf-Angular_thickness',\n",
    "'mrisdp_26' : 'lh_G_pariet_inf-Supramar_thickness',\n",
    "'mrisdp_27' : 'lh_G_parietal_sup_thickness',\n",
    "'mrisdp_28' : 'lh_G_postcentral_thickness',\n",
    "'mrisdp_29' : 'lh_G_precentral_thickness',\n",
    "'mrisdp_30' : 'lh_G_precuneus_thickness',\n",
    "'mrisdp_31' : 'lh_G_rectus_thickness',\n",
    "'mrisdp_32' : 'lh_G_subcallosal_thickness',\n",
    "'mrisdp_33' : 'lh_G_temp_sup-G_T_transv_thickness',\n",
    "'mrisdp_34' : 'lh_G_temp_sup-Lateral_thickness',\n",
    "'mrisdp_35' : 'lh_G_temp_sup-Plan_polar_thickness',\n",
    "'mrisdp_36' : 'lh_G_temp_sup-Plan_tempo_thickness',\n",
    "'mrisdp_37' : 'lh_G_temporal_inf_thickness',\n",
    "'mrisdp_38' : 'lh_G_temporal_middle_thickness',\n",
    "'mrisdp_39' : 'lh_Lat_Fis-ant-Horizont_thickness',\n",
    "'mrisdp_40' : 'lh_Lat_Fis-ant-Vertical_thickness',\n",
    "'mrisdp_41' : 'lh_Lat_Fis-post_thickness',\n",
    "'mrisdp_42' : 'lh_Pole_occipital_thickness',\n",
    "'mrisdp_43' : 'lh_Pole_temporal_thickness',\n",
    "'mrisdp_44' : 'lh_S_calcarine_thickness',\n",
    "'mrisdp_45' : 'lh_S_central_thickness',\n",
    "'mrisdp_46' : 'lh_S_cingul-Marginalis_thickness',\n",
    "'mrisdp_47' : 'lh_S_circular_insula_ant_thickness',\n",
    "'mrisdp_48' : 'lh_S_circular_insula_inf_thickness',\n",
    "'mrisdp_49' : 'lh_S_circular_insula_sup_thickness',\n",
    "'mrisdp_50' : 'lh_S_collat_transv_ant_thickness',\n",
    "'mrisdp_51' : 'lh_S_collat_transv_post_thickness',\n",
    "'mrisdp_52' : 'lh_S_front_inf_thickness',\n",
    "'mrisdp_53' : 'lh_S_front_middle_thickness',\n",
    "'mrisdp_54' : 'lh_S_front_sup_thickness',\n",
    "'mrisdp_55' : 'lh_S_interm_prim-Jensen_thickness',\n",
    "'mrisdp_56' : 'lh_S_intrapariet&P_trans_thickness',\n",
    "'mrisdp_57' : 'lh_S_oc_middle&Lunatus_thickness',\n",
    "'mrisdp_58' : 'lh_S_oc_sup&transversal_thickness',\n",
    "'mrisdp_59' : 'lh_S_occipital_ant_thickness',\n",
    "'mrisdp_60' : 'lh_S_oc-temp_lat_thickness',\n",
    "'mrisdp_61' : 'lh_S_oc-temp_med&Lingual_thickness',\n",
    "'mrisdp_62' : 'lh_S_orbital_lateral_thickness',\n",
    "'mrisdp_63' : 'lh_S_orbital_med-olfact_thickness',\n",
    "'mrisdp_64' : 'lh_S_orbital-H_Shaped_thickness',\n",
    "'mrisdp_65' : 'lh_S_parieto_occipital_thickness',\n",
    "'mrisdp_66' : 'lh_S_pericallosal_thickness',\n",
    "'mrisdp_67' : 'lh_S_postcentral_thickness',\n",
    "'mrisdp_68' : 'lh_S_precentral-inf-part_thickness',\n",
    "'mrisdp_69' : 'lh_S_precentral-sup-part_thickness',\n",
    "'mrisdp_70' : 'lh_S_suborbital_thickness',\n",
    "'mrisdp_71' : 'lh_S_subparietal_thickness',\n",
    "'mrisdp_72' : 'lh_S_temporal_inf_thickness',\n",
    "'mrisdp_73' : 'lh_S_temporal_sup_thickness',\n",
    "'mrisdp_74' : 'lh_S_temporal_transverse_thickness',\n",
    "'mrisdp_75' : 'rh_G&S_frontomargin_thickness',\n",
    "'mrisdp_76' : 'rh_G&S_occipital_inf_thickness',\n",
    "'mrisdp_77' : 'rh_G&S_paracentral_thickness',\n",
    "'mrisdp_78' : 'rh_G&S_subcentral_thickness',\n",
    "'mrisdp_79' : 'rh_G&S_transv_frontopol_thickness',\n",
    "'mrisdp_80' : 'rh_G&S_cingul-Ant_thickness',\n",
    "'mrisdp_81' : 'rh_G&S_cingul-Mid-Ant_thickness',\n",
    "'mrisdp_82' : 'rh_G&S_cingul-Mid-Post_thickness',\n",
    "'mrisdp_83' : 'rh_G_cingul-Post-dorsal_thickness',\n",
    "'mrisdp_84' : 'rh_G_cingul-Post-ventral_thickness',\n",
    "'mrisdp_85' : 'rh_G_cuneus_thickness',\n",
    "'mrisdp_86' : 'rh_G_front_inf-Opercular_thickness',\n",
    "'mrisdp_87' : 'rh_G_front_inf-Orbital_thickness',\n",
    "'mrisdp_88' : 'rh_G_front_inf-Triangul_thickness',\n",
    "'mrisdp_89' : 'rh_G_front_middle_thickness',\n",
    "'mrisdp_90' : 'rh_G_front_sup_thickness',\n",
    "'mrisdp_91' : 'rh_G_Ins_lg&S_cent_ins_thickness',\n",
    "'mrisdp_92' : 'rh_G_insular_short_thickness',\n",
    "'mrisdp_93' : 'rh_G_occipital_middle_thickness',\n",
    "'mrisdp_94' : 'rh_G_occipital_sup_thickness',\n",
    "'mrisdp_95' : 'rh_G_oc-temp_lat-fusifor_thickness',\n",
    "'mrisdp_96' : 'rh_G_oc-temp_med-Lingual_thickness',\n",
    "'mrisdp_97' : 'rh_G_oc-temp_med-Parahip_thickness',\n",
    "'mrisdp_98' : 'rh_G_orbital_thickness',\n",
    "'mrisdp_99' : 'rh_G_pariet_inf-Angular_thickness',\n",
    "'mrisdp_100' : 'rh_G_pariet_inf-Supramar_thickness',\n",
    "'mrisdp_101' : 'rh_G_parietal_sup_thickness',\n",
    "'mrisdp_102' : 'rh_G_postcentral_thickness',\n",
    "'mrisdp_103' : 'rh_G_precentral_thickness',\n",
    "'mrisdp_104' : 'rh_G_precuneus_thickness',\n",
    "'mrisdp_105' : 'rh_G_rectus_thickness',\n",
    "'mrisdp_106' : 'rh_G_subcallosal_thickness',\n",
    "'mrisdp_107' : 'rh_G_temp_sup-G_T_transv_thickness',\n",
    "'mrisdp_108' : 'rh_G_temp_sup-Lateral_thickness',\n",
    "'mrisdp_109' : 'rh_G_temp_sup-Plan_polar_thickness',\n",
    "'mrisdp_110' : 'rh_G_temp_sup-Plan_tempo_thickness',\n",
    "'mrisdp_111' : 'rh_G_temporal_inf_thickness',\n",
    "'mrisdp_112' : 'rh_G_temporal_middle_thickness',\n",
    "'mrisdp_113' : 'rh_Lat_Fis-ant-Horizont_thickness',\n",
    "'mrisdp_114' : 'rh_Lat_Fis-ant-Vertical_thickness',\n",
    "'mrisdp_115' : 'rh_Lat_Fis-post_thickness',\n",
    "'mrisdp_116' : 'rh_Pole_occipital_thickness',\n",
    "'mrisdp_117' : 'rh_Pole_temporal_thickness',\n",
    "'mrisdp_118' : 'rh_S_calcarine_thickness',\n",
    "'mrisdp_119' : 'rh_S_central_thickness',\n",
    "'mrisdp_120' : 'rh_S_cingul-Marginalis_thickness',\n",
    "'mrisdp_121' : 'rh_S_circular_insula_ant_thickness',\n",
    "'mrisdp_122' : 'rh_S_circular_insula_inf_thickness',\n",
    "'mrisdp_123' : 'rh_S_circular_insula_sup_thickness',\n",
    "'mrisdp_124' : 'rh_S_collat_transv_ant_thickness',\n",
    "'mrisdp_125' : 'rh_S_collat_transv_post_thickness',\n",
    "'mrisdp_126' : 'rh_S_front_inf_thickness',\n",
    "'mrisdp_127' : 'rh_S_front_middle_thickness',\n",
    "'mrisdp_128' : 'rh_S_front_sup_thickness',\n",
    "'mrisdp_129' : 'rh_S_interm_prim-Jensen_thickness',\n",
    "'mrisdp_130' : 'rh_S_intrapariet&P_trans_thickness',\n",
    "'mrisdp_131' : 'rh_S_oc_middle&Lunatus_thickness',\n",
    "'mrisdp_132' : 'rh_S_oc_sup&transversal_thickness',\n",
    "'mrisdp_133' : 'rh_S_occipital_ant_thickness',\n",
    "'mrisdp_134' : 'rh_S_oc-temp_lat_thickness',\n",
    "'mrisdp_135' : 'rh_S_oc-temp_med&Lingual_thickness',\n",
    "'mrisdp_136' : 'rh_S_orbital_lateral_thickness',\n",
    "'mrisdp_137' : 'rh_S_orbital_med-olfact_thickness',\n",
    "'mrisdp_138' : 'rh_S_orbital-H_Shaped_thickness',\n",
    "'mrisdp_139' : 'rh_S_parieto_occipital_thickness',\n",
    "'mrisdp_140' : 'rh_S_pericallosal_thickness',\n",
    "'mrisdp_141' : 'rh_S_postcentral_thickness',\n",
    "'mrisdp_142' : 'rh_S_precentral-inf-part_thickness',\n",
    "'mrisdp_143' : 'rh_S_precentral-sup-part_thickness',\n",
    "'mrisdp_144' : 'rh_S_suborbital_thickness',\n",
    "'mrisdp_145' : 'rh_S_subparietal_thickness',\n",
    "'mrisdp_146' : 'rh_S_temporal_inf_thickness',\n",
    "'mrisdp_147' : 'rh_S_temporal_sup_thickness',\n",
    "'mrisdp_148' : 'rh_S_temporal_transverse_thickness' }\n",
    "ABCD_AparcRename = ABCD_Aparc.rename(columns=Aparc_Dict)\n",
    "\n",
    "ABCD_Cortical = ABCD_AparcRename[['subjectkey', 'eventname', 'lh_G&S_frontomargin_thickness', 'lh_G&S_occipital_inf_thickness', 'lh_G&S_paracentral_thickness', 'lh_G&S_subcentral_thickness', 'lh_G&S_transv_frontopol_thickness', 'lh_G&S_cingul-Ant_thickness', 'lh_G&S_cingul-Mid-Ant_thickness', 'lh_G&S_cingul-Mid-Post_thickness', 'lh_G_cingul-Post-dorsal_thickness', 'lh_G_cingul-Post-ventral_thickness', 'lh_G_cuneus_thickness', 'lh_G_front_inf-Opercular_thickness', 'lh_G_front_inf-Orbital_thickness', 'lh_G_front_inf-Triangul_thickness', 'lh_G_front_middle_thickness', 'lh_G_front_sup_thickness', 'lh_G_Ins_lg&S_cent_ins_thickness', 'lh_G_insular_short_thickness', 'lh_G_occipital_middle_thickness', 'lh_G_occipital_sup_thickness', 'lh_G_oc-temp_lat-fusifor_thickness', 'lh_G_oc-temp_med-Lingual_thickness', 'lh_G_oc-temp_med-Parahip_thickness', 'lh_G_orbital_thickness', 'lh_G_pariet_inf-Angular_thickness', 'lh_G_pariet_inf-Supramar_thickness', 'lh_G_parietal_sup_thickness', 'lh_G_postcentral_thickness', 'lh_G_precentral_thickness', 'lh_G_precuneus_thickness', 'lh_G_rectus_thickness', 'lh_G_subcallosal_thickness', 'lh_G_temp_sup-G_T_transv_thickness', 'lh_G_temp_sup-Lateral_thickness', 'lh_G_temp_sup-Plan_polar_thickness', 'lh_G_temp_sup-Plan_tempo_thickness', 'lh_G_temporal_inf_thickness', 'lh_G_temporal_middle_thickness', 'lh_Lat_Fis-ant-Horizont_thickness', 'lh_Lat_Fis-ant-Vertical_thickness', 'lh_Lat_Fis-post_thickness', 'lh_Pole_occipital_thickness', 'lh_Pole_temporal_thickness', 'lh_S_calcarine_thickness', 'lh_S_central_thickness', 'lh_S_cingul-Marginalis_thickness', 'lh_S_circular_insula_ant_thickness', 'lh_S_circular_insula_inf_thickness', 'lh_S_circular_insula_sup_thickness', 'lh_S_collat_transv_ant_thickness', 'lh_S_collat_transv_post_thickness', 'lh_S_front_inf_thickness', 'lh_S_front_middle_thickness', 'lh_S_front_sup_thickness', 'lh_S_interm_prim-Jensen_thickness', 'lh_S_intrapariet&P_trans_thickness', 'lh_S_oc_middle&Lunatus_thickness', 'lh_S_oc_sup&transversal_thickness', 'lh_S_occipital_ant_thickness', 'lh_S_oc-temp_lat_thickness', 'lh_S_oc-temp_med&Lingual_thickness', 'lh_S_orbital_lateral_thickness', 'lh_S_orbital_med-olfact_thickness', 'lh_S_orbital-H_Shaped_thickness', 'lh_S_parieto_occipital_thickness', 'lh_S_pericallosal_thickness', 'lh_S_postcentral_thickness', 'lh_S_precentral-inf-part_thickness', 'lh_S_precentral-sup-part_thickness', 'lh_S_suborbital_thickness', 'lh_S_subparietal_thickness', 'lh_S_temporal_inf_thickness', 'lh_S_temporal_sup_thickness', 'lh_S_temporal_transverse_thickness', 'rh_G&S_frontomargin_thickness', 'rh_G&S_occipital_inf_thickness', 'rh_G&S_paracentral_thickness', 'rh_G&S_subcentral_thickness', 'rh_G&S_transv_frontopol_thickness', 'rh_G&S_cingul-Ant_thickness', 'rh_G&S_cingul-Mid-Ant_thickness', 'rh_G&S_cingul-Mid-Post_thickness', 'rh_G_cingul-Post-dorsal_thickness', 'rh_G_cingul-Post-ventral_thickness', 'rh_G_cuneus_thickness', 'rh_G_front_inf-Opercular_thickness', 'rh_G_front_inf-Orbital_thickness', 'rh_G_front_inf-Triangul_thickness', 'rh_G_front_middle_thickness', 'rh_G_front_sup_thickness', 'rh_G_Ins_lg&S_cent_ins_thickness', 'rh_G_insular_short_thickness', 'rh_G_occipital_middle_thickness', 'rh_G_occipital_sup_thickness', 'rh_G_oc-temp_lat-fusifor_thickness', 'rh_G_oc-temp_med-Lingual_thickness', 'rh_G_oc-temp_med-Parahip_thickness', 'rh_G_orbital_thickness', 'rh_G_pariet_inf-Angular_thickness', 'rh_G_pariet_inf-Supramar_thickness', 'rh_G_parietal_sup_thickness', 'rh_G_postcentral_thickness', 'rh_G_precentral_thickness', 'rh_G_precuneus_thickness', 'rh_G_rectus_thickness', 'rh_G_subcallosal_thickness', 'rh_G_temp_sup-G_T_transv_thickness', 'rh_G_temp_sup-Lateral_thickness', 'rh_G_temp_sup-Plan_polar_thickness', 'rh_G_temp_sup-Plan_tempo_thickness', 'rh_G_temporal_inf_thickness', 'rh_G_temporal_middle_thickness', 'rh_Lat_Fis-ant-Horizont_thickness', 'rh_Lat_Fis-ant-Vertical_thickness', 'rh_Lat_Fis-post_thickness', 'rh_Pole_occipital_thickness', 'rh_Pole_temporal_thickness', 'rh_S_calcarine_thickness', 'rh_S_central_thickness', 'rh_S_cingul-Marginalis_thickness', 'rh_S_circular_insula_ant_thickness', 'rh_S_circular_insula_inf_thickness', 'rh_S_circular_insula_sup_thickness', 'rh_S_collat_transv_ant_thickness', 'rh_S_collat_transv_post_thickness', 'rh_S_front_inf_thickness', 'rh_S_front_middle_thickness', 'rh_S_front_sup_thickness', 'rh_S_interm_prim-Jensen_thickness', 'rh_S_intrapariet&P_trans_thickness', 'rh_S_oc_middle&Lunatus_thickness', 'rh_S_oc_sup&transversal_thickness', 'rh_S_occipital_ant_thickness', 'rh_S_oc-temp_lat_thickness', 'rh_S_oc-temp_med&Lingual_thickness', 'rh_S_orbital_lateral_thickness', 'rh_S_orbital_med-olfact_thickness', 'rh_S_orbital-H_Shaped_thickness', 'rh_S_parieto_occipital_thickness', 'rh_S_pericallosal_thickness', 'rh_S_postcentral_thickness', 'rh_S_precentral-inf-part_thickness', 'rh_S_precentral-sup-part_thickness', 'rh_S_suborbital_thickness', 'rh_S_subparietal_thickness', 'rh_S_temporal_inf_thickness', 'rh_S_temporal_sup_thickness', 'rh_S_temporal_transverse_thickness']]\n",
    "\n",
    "\n",
    "Aseg_Dict = {'smri_vol_scs_hpuslh' : 'Left-Hippocampus', 'smri_vol_scs_amygdalalh' : 'Left-Amygdala', 'smri_vol_scs_hpusrh' : 'Right-Hippocampus', 'smri_vol_scs_amygdalarh' : 'Right-Amygdala', 'smri_vol_scs_intracranialv' : 'eICV'}\n",
    "ABCD_AsegRename = ABCD_Aseg.rename(columns=Aseg_Dict)\n",
    "         \n",
    "ABCD_Subcortical = ABCD_AsegRename[['subjectkey', 'eventname', 'Left-Hippocampus', 'Left-Amygdala', 'Right-Hippocampus',  'Right-Amygdala', 'eICV']]\n",
    "             \n",
    "             \n",
    "             \n",
    "             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca3b30f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Find any duplicates and remove them\n",
    "ABCD_Cortical.drop_duplicates()\n",
    "ABCD_Subcortical.drop_duplicates()\n",
    "ABCD_DemVars.drop_duplicates()\n",
    "ABCD_ResVars.drop_duplicates()\n",
    "ABCD_SiteVars.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff66a8ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Separate Datasets by their follow-up points and rename\n",
    "#ABCD_DemRes = ABCD_DemVars.merge(ABCD_ResVars, on=['subjectkey'], how='outer')\n",
    "Base_ABCD_Dem = ABCD_DemVars[ABCD_DemVars['eventname'] == 'baseline_year_1_arm_1']\n",
    "Base_ABCD_Long = ABCD_LongDemVars[ABCD_LongDemVars['eventname'] == 'baseline_year_1_arm_1']\n",
    "Second_ABCD_Long = ABCD_LongDemVars[ABCD_LongDemVars['eventname'] == '2_year_follow_up_y_arm_1']\n",
    "\n",
    "#Base_ABCD_Long = ABCD_LongDemVars[ABCD_LongDemVars['eventname'] == 'baseline_year_1_arm_1']\n",
    "#BaseLongDict = {'subjectkey', 'eventname', 'interview_age', 'sex', 'demo_comb_income_v2_l', 'demo_prnt_ed_v2_2yr_l', 'demo_prtnr_ed_v2_2yr_l', 'demo_prnt_empl_v2_l', 'demo_prtnr_empl_v2_l', 'demo_prnt_marital_v2_l'}\n",
    "#Base_ABCD_Long = Base_ABCD_Long.rename(columns=BaseLongDict)\n",
    "#Second_ABCD_Long = ABCD_LongDemVars[ABCD_LongDemVars['eventname'] == '2_year_follow_up_y_arm_1']\n",
    "#SecondLongDict = {'subjectkey', 'eventname', 'interview_age', 'sex', 'demo_comb_income_v2_l', 'demo_prnt_ed_v2_2yr_l', 'demo_prtnr_ed_v2_2yr_l', 'demo_prnt_empl_v2_l', 'demo_prtnr_empl_v2_l', 'demo_prnt_marital_v2_l''}\n",
    "#Second_ABCD_Long = Second_ABCD_Long.rename(columns=SecondLongDict)\n",
    "\n",
    "Base_ABCD_Res = ABCD_ResVars[ABCD_ResVars['eventname'] == 'baseline_year_1_arm_1']\n",
    "BaseResDict = {'reshist_addr1_adi_perc' : 'Base_ADI', 'reshist_addr1_no2' : 'Base_N02', 'reshist_addr1_pm25' : 'Base_PM25', 'reshist_state_racism_factor' : 'Base_Racism',  'reshist_addr1_coi_r_coi_nat' : 'Base_COI'}\n",
    "Base_ABCD_Res = Base_ABCD_Res.rename(columns=BaseResDict)\n",
    "Second_ABCD_Res = ABCD_ResVars[ABCD_ResVars['eventname'] == '2_year_follow_up_y_arm_1']\n",
    "SecondResDict = {'reshist_addr1_adi_perc' : '2nd_ADI', 'reshist_addr1_no2' : '2nd_N02', 'reshist_addr1_pm25' : '2nd_PM25', 'reshist_state_racism_factor' : '2nd_Racism',  'reshist_addr1_coi_r_coi_nat' : '2nd_COI'}\n",
    "Second_ABCD_Res = Second_ABCD_Res.rename(columns=SecondResDict)\n",
    "\n",
    "Base_ABCD_Site = ABCD_SiteVars[ABCD_SiteVars['eventname'] == 'baseline_year_1_arm_1']\n",
    "Second_ABCD_Site = ABCD_SiteVars[ABCD_SiteVars['eventname'] == '2_year_follow_up_y_arm_1']\n",
    "BaseSiteVar = {'site_id_l' : 'Base_Site'}\n",
    "SecondSiteVar = {'site_id_l' : '2nd_Site'}\n",
    "Base_ABCD_Site = Base_ABCD_Site.rename(columns=BaseSiteVar)\n",
    "Second_ABCD_Site = Second_ABCD_Site.rename(columns=SecondSiteVar)\n",
    "\n",
    "Base_ABCD_Aparc = ABCD_Cortical[ABCD_Cortical['eventname'] == 'baseline_year_1_arm_1']\n",
    "Second_ABCD_Aparc = ABCD_Cortical[ABCD_Cortical['eventname'] == '2_year_follow_up_y_arm_1']\n",
    "Second_ABCD_Aparc = Second_ABCD_Aparc.add_suffix('_2nd')\n",
    "Second_ABCD_Aparc = Second_ABCD_Aparc.rename(columns={'subjectkey_2nd' : 'subjectkey', 'eventname_2nd' : 'eventname'})\n",
    "\n",
    "Base_ABCD_Aseg = ABCD_Subcortical[ABCD_Subcortical['eventname'] == 'baseline_year_1_arm_1']\n",
    "Second_ABCD_Aseg = ABCD_Subcortical[ABCD_Subcortical['eventname'] == '2_year_follow_up_y_arm_1']\n",
    "Second_ABCD_Aseg = Second_ABCD_Aseg.add_suffix('_2nd')\n",
    "Second_ABCD_Aseg = Second_ABCD_Aseg.rename(columns={'subjectkey_2nd' : 'subjectkey', 'eventname_2nd' : 'eventname'})\n",
    "\n",
    "New_ABCD_Long = Base_ABCD_Long.merge(Second_ABCD_Long, on='subjectkey', how='left')\n",
    "New_ABCD_Res = Base_ABCD_Res.merge(Second_ABCD_Res, on='subjectkey', how='left')\n",
    "New_ABCD_Site = Base_ABCD_Site.merge(Second_ABCD_Site, on='subjectkey', how='left')\n",
    "New_Cortical = Base_ABCD_Aparc.merge(Second_ABCD_Aparc, on='subjectkey', how='left')\n",
    "New_Subcortical = Base_ABCD_Aseg.merge(Second_ABCD_Aseg, on='subjectkey', how='left')\n",
    "Dem0 = New_ABCD_Long.merge(Base_ABCD_Dem, on='subjectkey', how='left')\n",
    "Dem1 = Dem0.merge(New_ABCD_Res, on='subjectkey', how='left')\n",
    "ABCD_SocioDem = Dem1.merge(New_ABCD_Site, on='subjectkey', how='left')\n",
    "ABCD_PartFull = ABCD_SocioDem.merge(New_Cortical, on='subjectkey', how='left')\n",
    "ABCD_Full = ABCD_PartFull.merge(New_Subcortical, on='subjectkey', how='left')\n",
    "\n",
    "print(ABCD_Full)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c21b05a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Prepare Datasets Specifically for BrainCharts\n",
    "#NB: We can only use Year 2 info for this...so, we need to drop anything in the but the year 2 data\n",
    "\n",
    "BLR_Model_Data_2ndWave = ABCD_Full[['subjectkey', 'interview_age_y', 'sex_y', 'demo_race_a_p___10', 'demo_race_a_p___11', 'demo_race_a_p___12', 'demo_race_a_p___13', 'demo_race_a_p___14', 'demo_race_a_p___15', 'demo_race_a_p___16', 'demo_race_a_p___17', 'demo_race_a_p___18', 'demo_race_a_p___19', 'demo_race_a_p___20', 'demo_race_a_p___21', 'demo_race_a_p___22', 'demo_race_a_p___23', 'demo_race_a_p___24', 'demo_race_a_p___25', 'demo_race_a_p___77', 'demo_race_a_p___99', 'demo_comb_income_v2_l_y', 'demo_prnt_ed_v2_2yr_l_y', 'demo_prtnr_ed_v2_2yr_l_y', 'demo_prnt_empl_v2_l_y', 'demo_prtnr_empl_v2_l_y', 'demo_prnt_marital_v2_l_y', 'Base_ADI', 'Base_N02', 'Base_PM25', 'Base_Racism', 'Base_COI', 'eventname_y_y', '2nd_ADI', '2nd_N02', '2nd_PM25', '2nd_Racism', '2nd_COI', '2nd_Site', 'lh_G&S_frontomargin_thickness_2nd', 'lh_G&S_occipital_inf_thickness_2nd', 'lh_G&S_paracentral_thickness_2nd', 'lh_G&S_subcentral_thickness_2nd', 'lh_G&S_transv_frontopol_thickness_2nd', 'lh_G&S_cingul-Ant_thickness_2nd', 'lh_G&S_cingul-Mid-Ant_thickness_2nd', 'lh_G&S_cingul-Mid-Post_thickness_2nd', 'lh_G_cingul-Post-dorsal_thickness_2nd', 'lh_G_cingul-Post-ventral_thickness_2nd', 'lh_G_cuneus_thickness_2nd', 'lh_G_front_inf-Opercular_thickness_2nd', 'lh_G_front_inf-Orbital_thickness_2nd', 'lh_G_front_inf-Triangul_thickness_2nd', 'lh_G_front_middle_thickness_2nd', 'lh_G_front_sup_thickness_2nd', 'lh_G_Ins_lg&S_cent_ins_thickness_2nd', 'lh_G_insular_short_thickness_2nd', 'lh_G_occipital_middle_thickness_2nd', 'lh_G_occipital_sup_thickness_2nd', 'lh_G_oc-temp_lat-fusifor_thickness_2nd', 'lh_G_oc-temp_med-Lingual_thickness_2nd', 'lh_G_oc-temp_med-Parahip_thickness_2nd', 'lh_G_orbital_thickness_2nd', 'lh_G_pariet_inf-Angular_thickness_2nd', 'lh_G_pariet_inf-Supramar_thickness_2nd', 'lh_G_parietal_sup_thickness_2nd', 'lh_G_postcentral_thickness_2nd', 'lh_G_precentral_thickness_2nd', 'lh_G_precuneus_thickness_2nd', 'lh_G_rectus_thickness_2nd', 'lh_G_subcallosal_thickness_2nd', 'lh_G_temp_sup-G_T_transv_thickness_2nd', 'lh_G_temp_sup-Lateral_thickness_2nd', 'lh_G_temp_sup-Plan_polar_thickness_2nd', 'lh_G_temp_sup-Plan_tempo_thickness_2nd', 'lh_G_temporal_inf_thickness_2nd', 'lh_G_temporal_middle_thickness_2nd', 'lh_Lat_Fis-ant-Horizont_thickness_2nd', 'lh_Lat_Fis-ant-Vertical_thickness_2nd', 'lh_Lat_Fis-post_thickness_2nd', 'lh_Pole_occipital_thickness_2nd', 'lh_Pole_temporal_thickness_2nd', 'lh_S_calcarine_thickness_2nd', 'lh_S_central_thickness_2nd', 'lh_S_cingul-Marginalis_thickness_2nd', 'lh_S_circular_insula_ant_thickness_2nd', 'lh_S_circular_insula_inf_thickness_2nd', 'lh_S_circular_insula_sup_thickness_2nd', 'lh_S_collat_transv_ant_thickness_2nd', 'lh_S_collat_transv_post_thickness_2nd', 'lh_S_front_inf_thickness_2nd', 'lh_S_front_middle_thickness_2nd', 'lh_S_front_sup_thickness_2nd', 'lh_S_interm_prim-Jensen_thickness_2nd', 'lh_S_intrapariet&P_trans_thickness_2nd', 'lh_S_oc_middle&Lunatus_thickness_2nd', 'lh_S_oc_sup&transversal_thickness_2nd', 'lh_S_occipital_ant_thickness_2nd', 'lh_S_oc-temp_lat_thickness_2nd', 'lh_S_oc-temp_med&Lingual_thickness_2nd', 'lh_S_orbital_lateral_thickness_2nd', 'lh_S_orbital_med-olfact_thickness_2nd', 'lh_S_orbital-H_Shaped_thickness_2nd', 'lh_S_parieto_occipital_thickness_2nd', 'lh_S_pericallosal_thickness_2nd', 'lh_S_postcentral_thickness_2nd', 'lh_S_precentral-inf-part_thickness_2nd', 'lh_S_precentral-sup-part_thickness_2nd', 'lh_S_suborbital_thickness_2nd', 'lh_S_subparietal_thickness_2nd', 'lh_S_temporal_inf_thickness_2nd', 'lh_S_temporal_sup_thickness_2nd', 'lh_S_temporal_transverse_thickness_2nd', 'rh_G&S_frontomargin_thickness_2nd', 'rh_G&S_occipital_inf_thickness_2nd', 'rh_G&S_paracentral_thickness_2nd', 'rh_G&S_subcentral_thickness_2nd', 'rh_G&S_transv_frontopol_thickness_2nd', 'rh_G&S_cingul-Ant_thickness_2nd', 'rh_G&S_cingul-Mid-Ant_thickness_2nd', 'rh_G&S_cingul-Mid-Post_thickness_2nd', 'rh_G_cingul-Post-dorsal_thickness_2nd', 'rh_G_cingul-Post-ventral_thickness_2nd', 'rh_G_cuneus_thickness_2nd', 'rh_G_front_inf-Opercular_thickness_2nd', 'rh_G_front_inf-Orbital_thickness_2nd', 'rh_G_front_inf-Triangul_thickness_2nd', 'rh_G_front_middle_thickness_2nd', 'rh_G_front_sup_thickness_2nd', 'rh_G_Ins_lg&S_cent_ins_thickness_2nd', 'rh_G_insular_short_thickness_2nd', 'rh_G_occipital_middle_thickness_2nd', 'rh_G_occipital_sup_thickness_2nd', 'rh_G_oc-temp_lat-fusifor_thickness_2nd', 'rh_G_oc-temp_med-Lingual_thickness_2nd', 'rh_G_oc-temp_med-Parahip_thickness_2nd', 'rh_G_orbital_thickness_2nd', 'rh_G_pariet_inf-Angular_thickness_2nd', 'rh_G_pariet_inf-Supramar_thickness_2nd', 'rh_G_parietal_sup_thickness_2nd', 'rh_G_postcentral_thickness_2nd', 'rh_G_precentral_thickness_2nd', 'rh_G_precuneus_thickness_2nd', 'rh_G_rectus_thickness_2nd', 'rh_G_subcallosal_thickness_2nd', 'rh_G_temp_sup-G_T_transv_thickness_2nd', 'rh_G_temp_sup-Lateral_thickness_2nd', 'rh_G_temp_sup-Plan_polar_thickness_2nd', 'rh_G_temp_sup-Plan_tempo_thickness_2nd', 'rh_G_temporal_inf_thickness_2nd', 'rh_G_temporal_middle_thickness_2nd', 'rh_Lat_Fis-ant-Horizont_thickness_2nd', 'rh_Lat_Fis-ant-Vertical_thickness_2nd', 'rh_Lat_Fis-post_thickness_2nd', 'rh_Pole_occipital_thickness_2nd', 'rh_Pole_temporal_thickness_2nd', 'rh_S_calcarine_thickness_2nd', 'rh_S_central_thickness_2nd', 'rh_S_cingul-Marginalis_thickness_2nd', 'rh_S_circular_insula_ant_thickness_2nd', 'rh_S_circular_insula_inf_thickness_2nd', 'rh_S_circular_insula_sup_thickness_2nd', 'rh_S_collat_transv_ant_thickness_2nd', 'rh_S_collat_transv_post_thickness_2nd', 'rh_S_front_inf_thickness_2nd', 'rh_S_front_middle_thickness_2nd', 'rh_S_front_sup_thickness_2nd', 'rh_S_interm_prim-Jensen_thickness_2nd', 'rh_S_intrapariet&P_trans_thickness_2nd', 'rh_S_oc_middle&Lunatus_thickness_2nd', 'rh_S_oc_sup&transversal_thickness_2nd', 'rh_S_occipital_ant_thickness_2nd', 'rh_S_oc-temp_lat_thickness_2nd', 'rh_S_oc-temp_med&Lingual_thickness_2nd', 'rh_S_orbital_lateral_thickness_2nd', 'rh_S_orbital_med-olfact_thickness_2nd', 'rh_S_orbital-H_Shaped_thickness_2nd', 'rh_S_parieto_occipital_thickness_2nd', 'rh_S_pericallosal_thickness_2nd', 'rh_S_postcentral_thickness_2nd', 'rh_S_precentral-inf-part_thickness_2nd', 'rh_S_precentral-sup-part_thickness_2nd', 'rh_S_suborbital_thickness_2nd', 'rh_S_subparietal_thickness_2nd', 'rh_S_temporal_inf_thickness_2nd', 'rh_S_temporal_sup_thickness_2nd', 'rh_S_temporal_transverse_thickness_2nd', 'Left-Hippocampus_2nd', 'Left-Amygdala_2nd', 'Right-Hippocampus_2nd', 'Right-Amygdala_2nd']]\n",
    "GenderDict = {\"M\" : '1', \"F\" : '0'}\n",
    "BLR_Model_Data_2ndWave = BLR_Model_Data_2ndWave.replace({'sex_y' : GenderDict})\n",
    "BLR_Model_Data_2ndWave = BLR_Model_Data_2ndWave.dropna(subset=['Left-Hippocampus_2nd'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f91b062",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Prep PCN Toolkit\n",
    "os.chdir(WorkingDir)\n",
    "BLR_Model_Data_2ndWave['age'] = BLR_Model_Data_2ndWave['interview_age_y'].astype(int)/12\n",
    "BLR_Model_Data_2ndWave['sex'] = BLR_Model_Data_2ndWave['sex_y']\n",
    "BLR_Model_Data_2ndWave['site'] = BLR_Model_Data_2ndWave['2nd_Site']\n",
    "\n",
    "SiteDict = {'site01' : 'ABCD_01', 'site02' : 'ABCD_02', 'site03' : 'ABCD_03', 'site04' : 'ABCD_04', 'site05' : 'ABCD_05', 'site06' : 'ABCD_06', 'site07' : 'ABCD_07', 'site08' : 'ABCD_08', 'site09' : 'ABCD_09', 'site10' : 'ABCD_10', 'site11' : 'ABCD_11', 'site12' : 'ABCD_12', 'site13' : 'ABCD_13', 'site14' : 'ABCD_14', 'site15' : 'ABCD_15', 'site16' : 'ABCD_16', 'site17' : 'ABCD_17', 'site18' : 'ABCD_18', 'site19' : 'ABCD_19', 'site20' : 'ABCD_20', 'site21' : 'ABCD_21'}\n",
    "BLR_Model_Data_2ndWave = BLR_Model_Data_2ndWave.replace({'site' : SiteDict})\n",
    "BLR_Model_Data_2ndWave.columns = BLR_Model_Data_2ndWave.columns.str.rstrip('_2nd')\n",
    "print(BLR_Model_Data_2ndWave)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322fdd45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##Print Dataset\n",
    "\n",
    "BLR_Model_Data_2ndWave_unique = BLR_Model_Data_2ndWave.drop_duplicates()\n",
    "print(BLR_Model_Data_2ndWave_unique)\n",
    "#BLR_Model_Data_2ndWave_unique.to_csv('BLR_Model_Data_2ndWave.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6e6be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Run the BrainCharts Transfer for the HCP Portion of the Analysis ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8c52c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Unzip Pretrained Models\n",
    "os.chdir(os.path.join(BrainChartsDir,'models/'))\n",
    "#! unzip lifespan_57K_82sites.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb17f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure Model Variables\n",
    "# which model do we wish to use?\n",
    "model_name = 'lifespan_57K_82sites'\n",
    "site_names = 'site_ids_ct_82sites.txt'\n",
    "\n",
    "# where the analysis takes place\n",
    "root_dir = WorkingDir\n",
    "\n",
    "# where the data files live\n",
    "data_dir = os.path.join(BrainChartsDir,'docs')\n",
    "\n",
    "# where the models live\n",
    "out_dir = os.path.join(BrainChartsDir, 'models', model_name)\n",
    "\n",
    "# load a set of site ids from this model. This must match the training data\n",
    "with open(os.path.join(BrainChartsDir,'docs', site_names)) as f:\n",
    "    site_ids_tr = f.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4648133",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Test Data\n",
    "\n",
    "#Note, we are going to use data derived from the 'SRG_2023_HCP_PCN_Analyses_04_25_23' notebook to start. We will need\n",
    "#fix a couple things for full use including grabbing site informaiton. Do not use this for publication or post to github\n",
    "#other than to demonstrate the inner workings of your mind\n",
    "\n",
    "# Big fix is to grab all HCP-A/D site info from the ndar_subject01 file. Also change interview_age to age. We may also need to\n",
    "# switch the 0 and 1 for sex but then we're good to go.\n",
    "\n",
    "test_data = os.path.join(WorkingDir,'BLR_Model_Data_2ndWave.csv')\n",
    "df_te = pd.read_csv(test_data)\n",
    "# extract a list of unique site ids from the test set\n",
    "\n",
    "site_ids_te =  sorted(set(df_te['site'].to_list()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c819e126",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(BLR_Model_Data_2ndWave['sex_y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ecfdfa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adaptation Dataset \n",
    "#adaptation_data = os.path.join(data_dir, 'OpenNeuroTransfer_ct_ad.csv')\n",
    "#\n",
    "#df_ad = pd.read_csv(adaptation_data)\n",
    "#\n",
    "## extract a list of unique site ids from the test set\n",
    "#site_ids_ad =  sorted(set(df_ad['site'].to_list()))\n",
    "#\n",
    "#if not all(elem in site_ids_ad for elem in site_ids_te):\n",
    "#    print('Warning: some of the testing sites are not in the adaptation data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e23a1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify IDPs and Covariates\n",
    "idp_ids = ['lh_G&S_frontomargin_thickness', 'lh_G&S_occipital_inf_thickness', 'lh_G&S_paracentral_thickness', 'lh_G&S_subcentral_thickness', 'lh_G&S_transv_frontopol_thickness', 'lh_G&S_cingul-Ant_thickness', 'lh_G&S_cingul-Mid-Ant_thickness', 'lh_G&S_cingul-Mid-Post_thickness', 'lh_G_cingul-Post-dorsal_thickness', 'lh_G_cingul-Post-ventral_thickness', 'lh_G_cuneus_thickness', 'lh_G_front_inf-Opercular_thickness', 'lh_G_front_inf-Orbital_thickness', 'lh_G_front_inf-Triangul_thickness', 'lh_G_front_middle_thickness', 'lh_G_front_sup_thickness', 'lh_G_Ins_lg&S_cent_ins_thickness', 'lh_G_insular_short_thickness', 'lh_G_occipital_middle_thickness', 'lh_G_occipital_sup_thickness', 'lh_G_oc-temp_lat-fusifor_thickness', 'lh_G_oc-temp_med-Lingual_thickness', 'lh_G_oc-temp_med-Parahip_thickness', 'lh_G_orbital_thickness', 'lh_G_pariet_inf-Angular_thickness', 'lh_G_pariet_inf-Supramar_thickness', 'lh_G_parietal_sup_thickness', 'lh_G_postcentral_thickness', 'lh_G_precentral_thickness', 'lh_G_precuneus_thickness', 'lh_G_rectus_thickness', 'lh_G_subcallosal_thickness', 'lh_G_temp_sup-G_T_transv_thickness', 'lh_G_temp_sup-Lateral_thickness', 'lh_G_temp_sup-Plan_polar_thickness', 'lh_G_temp_sup-Plan_tempo_thickness', 'lh_G_temporal_inf_thickness', 'lh_G_temporal_middle_thickness', 'lh_Lat_Fis-ant-Horizont_thickness', 'lh_Lat_Fis-ant-Vertical_thickness', 'lh_Lat_Fis-post_thickness', 'lh_Pole_occipital_thickness', 'lh_Pole_temporal_thickness', 'lh_S_calcarine_thickness', 'lh_S_central_thickness', 'lh_S_cingul-Marginalis_thickness', 'lh_S_circular_insula_ant_thickness', 'lh_S_circular_insula_inf_thickness', 'lh_S_circular_insula_sup_thickness', 'lh_S_collat_transv_ant_thickness', 'lh_S_collat_transv_post_thickness', 'lh_S_front_inf_thickness', 'lh_S_front_middle_thickness', 'lh_S_front_sup_thickness', 'lh_S_interm_prim-Jensen_thickness', 'lh_S_intrapariet&P_trans_thickness', 'lh_S_oc_middle&Lunatus_thickness', 'lh_S_oc_sup&transversal_thickness', 'lh_S_occipital_ant_thickness', 'lh_S_oc-temp_lat_thickness', 'lh_S_oc-temp_med&Lingual_thickness', 'lh_S_orbital_lateral_thickness', 'lh_S_orbital_med-olfact_thickness', 'lh_S_orbital-H_Shaped_thickness', 'lh_S_parieto_occipital_thickness', 'lh_S_pericallosal_thickness', 'lh_S_postcentral_thickness', 'lh_S_precentral-inf-part_thickness', 'lh_S_precentral-sup-part_thickness', 'lh_S_suborbital_thickness', 'lh_S_subparietal_thickness', 'lh_S_temporal_inf_thickness', 'lh_S_temporal_sup_thickness', 'lh_S_temporal_transverse_thickness', 'rh_G&S_frontomargin_thickness', 'rh_G&S_occipital_inf_thickness', 'rh_G&S_paracentral_thickness', 'rh_G&S_subcentral_thickness', 'rh_G&S_transv_frontopol_thickness', 'rh_G&S_cingul-Ant_thickness', 'rh_G&S_cingul-Mid-Ant_thickness', 'rh_G&S_cingul-Mid-Post_thickness', 'rh_G_cingul-Post-dorsal_thickness', 'rh_G_cingul-Post-ventral_thickness', 'rh_G_cuneus_thickness', 'rh_G_front_inf-Opercular_thickness', 'rh_G_front_inf-Orbital_thickness', 'rh_G_front_inf-Triangul_thickness', 'rh_G_front_middle_thickness', 'rh_G_front_sup_thickness', 'rh_G_Ins_lg&S_cent_ins_thickness', 'rh_G_insular_short_thickness', 'rh_G_occipital_middle_thickness', 'rh_G_occipital_sup_thickness', 'rh_G_oc-temp_lat-fusifor_thickness', 'rh_G_oc-temp_med-Lingual_thickness', 'rh_G_oc-temp_med-Parahip_thickness', 'rh_G_orbital_thickness', 'rh_G_pariet_inf-Angular_thickness', 'rh_G_pariet_inf-Supramar_thickness', 'rh_G_parietal_sup_thickness', 'rh_G_postcentral_thickness', 'rh_G_precentral_thickness', 'rh_G_precuneus_thickness', 'rh_G_rectus_thickness', 'rh_G_subcallosal_thickness', 'rh_G_temp_sup-G_T_transv_thickness', 'rh_G_temp_sup-Lateral_thickness', 'rh_G_temp_sup-Plan_polar_thickness', 'rh_G_temp_sup-Plan_tempo_thickness', 'rh_G_temporal_inf_thickness', 'rh_G_temporal_middle_thickness', 'rh_Lat_Fis-ant-Horizont_thickness', 'rh_Lat_Fis-ant-Vertical_thickness', 'rh_Lat_Fis-post_thickness', 'rh_Pole_occipital_thickness', 'rh_Pole_temporal_thickness', 'rh_S_calcarine_thickness', 'rh_S_central_thickness', 'rh_S_cingul-Marginalis_thickness', 'rh_S_circular_insula_ant_thickness', 'rh_S_circular_insula_inf_thickness', 'rh_S_circular_insula_sup_thickness', 'rh_S_collat_transv_ant_thickness', 'rh_S_collat_transv_post_thickness', 'rh_S_front_inf_thickness', 'rh_S_front_middle_thickness', 'rh_S_front_sup_thickness', 'rh_S_interm_prim-Jensen_thickness', 'rh_S_intrapariet&P_trans_thickness', 'rh_S_oc_middle&Lunatus_thickness', 'rh_S_oc_sup&transversal_thickness', 'rh_S_occipital_ant_thickness', 'rh_S_oc-temp_lat_thickness', 'rh_S_oc-temp_med&Lingual_thickness', 'rh_S_orbital_lateral_thickness', 'rh_S_orbital_med-olfact_thickness', 'rh_S_orbital-H_Shaped_thickness', 'rh_S_parieto_occipital_thickness', 'rh_S_pericallosal_thickness', 'rh_S_postcentral_thickness', 'rh_S_precentral-inf-part_thickness', 'rh_S_precentral-sup-part_thickness', 'rh_S_suborbital_thickness', 'rh_S_subparietal_thickness', 'rh_S_temporal_inf_thickness', 'rh_S_temporal_sup_thickness', 'rh_S_temporal_transverse_thickness', 'Left-Hippocampus', 'Left-Amygdala','Right-Hippocampus', 'Right-Amygdala', ]\n",
    "\n",
    "# which data columns do we wish to use as covariates? \n",
    "cols_cov = ['age','sex']\n",
    "\n",
    "# limits for cubic B-spline basis \n",
    "xmin = -5 \n",
    "xmax = 110\n",
    "\n",
    "# Absolute Z treshold above which a sample is considered to be an outlier (without fitting any model)\n",
    "outlier_thresh = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d97ee89",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Predictions for each IDP\n",
    "\n",
    "for idp_num, idp in enumerate(idp_ids): \n",
    "    print('Running IDP', idp_num, idp, ':')\n",
    "    idp_dir = os.path.join(out_dir, idp)\n",
    "    os.chdir(idp_dir)\n",
    "    \n",
    "    # extract and save the response variables for the test set\n",
    "    y_te = df_te[idp].to_numpy()\n",
    "    \n",
    "    # save the variables\n",
    "    resp_file_te = os.path.join(idp_dir, 'resp_te.txt') \n",
    "    np.savetxt(resp_file_te, y_te)\n",
    "        \n",
    "    # configure and save the design matrix\n",
    "    cov_file_te = os.path.join(idp_dir, 'cov_bspline_te.txt')\n",
    "    X_te = create_design_matrix(df_te[cols_cov], \n",
    "                                site_ids = df_te['site'],\n",
    "                                all_sites = site_ids_tr,\n",
    "                                basis = 'bspline', \n",
    "                                xmin = xmin, \n",
    "                                xmax = xmax)\n",
    "    ###Modified Save to Fix some random issue###\n",
    "    np.savetxt(cov_file_te, X_te, fmt='%s')\n",
    "    \n",
    "    # check whether all sites in the test set are represented in the training set\n",
    "    if all(elem in site_ids_tr for elem in site_ids_te):\n",
    "        print('All sites are present in the training data')\n",
    "        \n",
    "        # just make predictions\n",
    "        yhat_te, s2_te, Z = predict(cov_file_te, \n",
    "                                    alg='blr', \n",
    "                                    respfile=resp_file_te, \n",
    "                                    model_path=os.path.join(idp_dir,'Models'))\n",
    "    else:\n",
    "        print('Some sites missing from the training data. Adapting model')\n",
    "        \n",
    "        # save the covariates for the adaptation data\n",
    "        X_ad = create_design_matrix(df_ad[cols_cov], \n",
    "                                    site_ids = df_ad['site'],\n",
    "                                    all_sites = site_ids_tr,\n",
    "                                    basis = 'bspline', \n",
    "                                    xmin = xmin, \n",
    "                                    xmax = xmax)\n",
    "        cov_file_ad = os.path.join(idp_dir, 'cov_bspline_ad.txt')          \n",
    "        np.savetxt(cov_file_ad, X_ad)\n",
    "        \n",
    "        # save the responses for the adaptation data\n",
    "        resp_file_ad = os.path.join(idp_dir, 'resp_ad.txt') \n",
    "        y_ad = df_ad[idp].to_numpy()\n",
    "        np.savetxt(resp_file_ad, y_ad)\n",
    "       \n",
    "        # save the site ids for the adaptation data\n",
    "        sitenum_file_ad = os.path.join(idp_dir, 'sitenum_ad.txt') \n",
    "        site_num_ad = df_ad['sitenum'].to_numpy(dtype=int)\n",
    "        np.savetxt(sitenum_file_ad, site_num_ad)\n",
    "        \n",
    "        # save the site ids for the test data \n",
    "        sitenum_file_te = os.path.join(idp_dir, 'sitenum_te.txt')\n",
    "        site_num_te = df_te['sitenum'].to_numpy(dtype=int)\n",
    "        np.savetxt(sitenum_file_te, site_num_te)\n",
    "         \n",
    "        yhat_te, s2_te, Z = predict(cov_file_te, \n",
    "                                    alg = 'blr', \n",
    "                                    respfile = resp_file_te, \n",
    "                                    model_path = os.path.join(idp_dir,'Models'),\n",
    "                                    adaptrespfile = resp_file_ad,\n",
    "                                    adaptcovfile = cov_file_ad,\n",
    "                                    adaptvargroupfile = sitenum_file_ad,\n",
    "                                    testvargroupfile = sitenum_file_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0e85a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Centile Plots by Covariate\n",
    "# which sex do we want to plot? \n",
    "sex = 1 # 1 = male 0 = female\n",
    "if sex == 1: \n",
    "    clr = 'blue';\n",
    "else:\n",
    "    clr = 'red'\n",
    "\n",
    "# create dummy data for visualisation\n",
    "print('configuring dummy data ...')\n",
    "xx = np.arange(xmin, xmax, 0.5)\n",
    "X0_dummy = np.zeros((len(xx), 2))\n",
    "X0_dummy[:,0] = xx\n",
    "X0_dummy[:,1] = sex\n",
    "\n",
    "# create the design matrix\n",
    "X_dummy = create_design_matrix(X0_dummy, xmin=xmin, xmax=xmax, site_ids=None, all_sites=site_ids_tr)\n",
    "\n",
    "# save the dummy covariates\n",
    "cov_file_dummy = os.path.join(out_dir,'cov_bspline_dummy_mean.txt')\n",
    "np.savetxt(cov_file_dummy, X_dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1278a8b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sns.set(style='whitegrid')\n",
    "\n",
    "for idp_num, idp in enumerate(idp_ids): \n",
    "    print('Running IDP', idp_num, idp, ':')\n",
    "    idp_dir = os.path.join(out_dir, idp)\n",
    "    os.chdir(idp_dir)\n",
    "    \n",
    "    # load the true data points\n",
    "    yhat_te = load_2d(os.path.join(idp_dir, 'yhat_predict.txt'))\n",
    "    s2_te = load_2d(os.path.join(idp_dir, 'ys2_predict.txt'))\n",
    "    y_te = load_2d(os.path.join(idp_dir, 'resp_te.txt'))\n",
    "            \n",
    "    # set up the covariates for the dummy data\n",
    "    print('Making predictions with dummy covariates (for visualisation)')\n",
    "    yhat, s2 = predict(cov_file_dummy, \n",
    "                       alg = 'blr', \n",
    "                       respfile = None, \n",
    "                       model_path = os.path.join(idp_dir,'Models'), \n",
    "                       outputsuffix = '_dummy')\n",
    "    \n",
    "    # load the normative model\n",
    "    with open(os.path.join(idp_dir,'Models', 'NM_0_0_estimate.pkl'), 'rb') as handle:\n",
    "        nm = pickle.load(handle) \n",
    "    \n",
    "    # get the warp and warp parameters\n",
    "    W = nm.blr.warp\n",
    "    warp_param = nm.blr.hyp[1:nm.blr.warp.get_n_params()+1] \n",
    "        \n",
    "    # first, we warp predictions for the true data and compute evaluation metrics\n",
    "    med_te = W.warp_predictions(np.squeeze(yhat_te), np.squeeze(s2_te), warp_param)[0]\n",
    "    med_te = med_te[:, np.newaxis]\n",
    "    print('metrics:', evaluate(y_te, med_te))\n",
    "    \n",
    "    # then, we warp dummy predictions to create the plots\n",
    "    med, pr_int = W.warp_predictions(np.squeeze(yhat), np.squeeze(s2), warp_param)\n",
    "    \n",
    "    # extract the different variance components to visualise\n",
    "    beta, junk1, junk2 = nm.blr._parse_hyps(nm.blr.hyp, X_dummy)\n",
    "    s2n = 1/beta # variation (aleatoric uncertainty)\n",
    "    s2s = s2-s2n # modelling uncertainty (epistemic uncertainty)\n",
    "    \n",
    "    # plot the data points\n",
    "    y_te_rescaled_all = np.zeros_like(y_te)\n",
    "    for sid, site in enumerate(site_ids_te):\n",
    "        # plot the true test data points \n",
    "        if all(elem in site_ids_tr for elem in site_ids_te):\n",
    "            # all data in the test set are present in the training set\n",
    "            \n",
    "            # first, we select the data points belonging to this particular site\n",
    "            idx = np.where(np.bitwise_and(X_te[:,2] == sex, X_te[:,sid+len(cols_cov)+1] !=0))[0]\n",
    "            if len(idx) == 0:\n",
    "                print('No data for site', sid, site, 'skipping...')\n",
    "                continue\n",
    "            \n",
    "            # then directly adjust the data\n",
    "            idx_dummy = np.bitwise_and(X_dummy[:,1] > X_te[idx,1].min(), X_dummy[:,1] < X_te[idx,1].max())\n",
    "            y_te_rescaled = y_te[idx] - np.median(y_te[idx]) + np.median(med[idx_dummy])\n",
    "        else:\n",
    "            # we need to adjust the data based on the adaptation dataset \n",
    "            \n",
    "            # first, select the data point belonging to this particular site\n",
    "            idx = np.where(np.bitwise_and(X_te[:,2] == sex, (df_te['site'] == site).to_numpy()))[0]\n",
    "            \n",
    "            # load the adaptation data\n",
    "            y_ad = load_2d(os.path.join(idp_dir, 'resp_ad.txt'))\n",
    "            X_ad = load_2d(os.path.join(idp_dir, 'cov_bspline_ad.txt'))\n",
    "            idx_a = np.where(np.bitwise_and(X_ad[:,2] == sex, (df_ad['site'] == site).to_numpy()))[0]\n",
    "            if len(idx) < 2 or len(idx_a) < 2:\n",
    "                print('Insufficent data for site', sid, site, 'skipping...')\n",
    "                continue\n",
    "            \n",
    "            # adjust and rescale the data\n",
    "            y_te_rescaled, s2_rescaled = nm.blr.predict_and_adjust(nm.blr.hyp, \n",
    "                                                                   X_ad[idx_a,:], \n",
    "                                                                   np.squeeze(y_ad[idx_a]), \n",
    "                                                                   Xs=None, \n",
    "                                                                   ys=np.squeeze(y_te[idx]))\n",
    "        # plot the (adjusted) data points\n",
    "        plt.scatter(X_te[idx,1], y_te_rescaled, s=4, color=clr, alpha = 0.1)\n",
    "       \n",
    "    # plot the median of the dummy data\n",
    "    plt.plot(xx, med, clr)\n",
    "    \n",
    "    # fill the gaps in between the centiles\n",
    "    junk, pr_int25 = W.warp_predictions(np.squeeze(yhat), np.squeeze(s2), warp_param, percentiles=[0.25,0.75])\n",
    "    junk, pr_int95 = W.warp_predictions(np.squeeze(yhat), np.squeeze(s2), warp_param, percentiles=[0.05,0.95])\n",
    "    junk, pr_int99 = W.warp_predictions(np.squeeze(yhat), np.squeeze(s2), warp_param, percentiles=[0.01,0.99])\n",
    "    plt.fill_between(xx, pr_int25[:,0], pr_int25[:,1], alpha = 0.1,color=clr)\n",
    "    plt.fill_between(xx, pr_int95[:,0], pr_int95[:,1], alpha = 0.1,color=clr)\n",
    "    plt.fill_between(xx, pr_int99[:,0], pr_int99[:,1], alpha = 0.1,color=clr)\n",
    "            \n",
    "    # make the width of each centile proportional to the epistemic uncertainty\n",
    "    junk, pr_int25l = W.warp_predictions(np.squeeze(yhat), np.squeeze(s2-0.5*s2s), warp_param, percentiles=[0.25,0.75])\n",
    "    junk, pr_int95l = W.warp_predictions(np.squeeze(yhat), np.squeeze(s2-0.5*s2s), warp_param, percentiles=[0.05,0.95])\n",
    "    junk, pr_int99l = W.warp_predictions(np.squeeze(yhat), np.squeeze(s2-0.5*s2s), warp_param, percentiles=[0.01,0.99])\n",
    "    junk, pr_int25u = W.warp_predictions(np.squeeze(yhat), np.squeeze(s2+0.5*s2s), warp_param, percentiles=[0.25,0.75])\n",
    "    junk, pr_int95u = W.warp_predictions(np.squeeze(yhat), np.squeeze(s2+0.5*s2s), warp_param, percentiles=[0.05,0.95])\n",
    "    junk, pr_int99u = W.warp_predictions(np.squeeze(yhat), np.squeeze(s2+0.5*s2s), warp_param, percentiles=[0.01,0.99])    \n",
    "    plt.fill_between(xx, pr_int25l[:,0], pr_int25u[:,0], alpha = 0.3,color=clr)\n",
    "    plt.fill_between(xx, pr_int95l[:,0], pr_int95u[:,0], alpha = 0.3,color=clr)\n",
    "    plt.fill_between(xx, pr_int99l[:,0], pr_int99u[:,0], alpha = 0.3,color=clr)\n",
    "    plt.fill_between(xx, pr_int25l[:,1], pr_int25u[:,1], alpha = 0.3,color=clr)\n",
    "    plt.fill_between(xx, pr_int95l[:,1], pr_int95u[:,1], alpha = 0.3,color=clr)\n",
    "    plt.fill_between(xx, pr_int99l[:,1], pr_int99u[:,1], alpha = 0.3,color=clr)\n",
    "\n",
    "    # plot actual centile lines\n",
    "    plt.plot(xx, pr_int25[:,0],color=clr, linewidth=0.5)\n",
    "    plt.plot(xx, pr_int25[:,1],color=clr, linewidth=0.5)\n",
    "    plt.plot(xx, pr_int95[:,0],color=clr, linewidth=0.5)\n",
    "    plt.plot(xx, pr_int95[:,1],color=clr, linewidth=0.5)\n",
    "    plt.plot(xx, pr_int99[:,0],color=clr, linewidth=0.5)\n",
    "    plt.plot(xx, pr_int99[:,1],color=clr, linewidth=0.5)\n",
    "    \n",
    "    plt.xlabel('Age')\n",
    "    plt.ylabel(idp) \n",
    "    plt.title(idp)\n",
    "    plt.xlim((0,90))\n",
    "    plt.savefig(os.path.join(idp_dir, 'centiles_' + str(sex)),  bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "os.chdir(out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c5f984",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Get the DeviationScores togeher\n",
    "iterator = 1\n",
    "Z_Spread = pd.DataFrame()\n",
    "\n",
    "for idp_num, idp in enumerate(idp_ids): \n",
    "    idp_dir = os.path.join(out_dir, idp)\n",
    "    os.chdir(idp_dir)\n",
    "    col_name = 'Z_' + idp\n",
    "    Zvalues = pd.read_csv('Z_predict.txt',header=None)\n",
    "    Z_Spread.loc[:, col_name] = Zvalues\n",
    "    iterator += 1 \n",
    "\n",
    "\n",
    "print(Z_Spread)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfecc74-0ae9-4677-b0bf-b6bbe2e5f7cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Properly Merge Data\n",
    "\n",
    "Z_Data = Z_Spread\n",
    "Z_Data['subjectkey'] = BLR_Model_Data_2ndWave_unique['subjectkey'].values\n",
    "print(Z_Data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a450ea94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make Final Data\n",
    "#os.chdir(WorkingDir)\n",
    "#FinalDataset = BLR_Model_Data_2ndWave_unique.join(Z_Spread)\n",
    "#FinalDataset.to_csv('BLR_Transfer_FinalDataset_05_31_23.csv')\n",
    "#Z_Spread.to_csv('Z_Deviations_Full_02_23_24.csv')\n",
    "#BLR_Model_Data_2ndWave_unique.to_csv('BLR_Model_Data_2ndWave_02_23_24.csv')\n",
    "\n",
    "### NOTE: This section isn't actually used given a previous dumb error where I accidentally merged things wrong.\n",
    "### Removal of non-white/black participants happened offline for this section, hence why later files called are named\n",
    "### \"_forRandSPSS\" as those are then used. This really is just some logic to remove participants who did not\n",
    "### only report being \"white\" or \"black.\" Sorry about that potential reader. There IS a variable the ABCD team\n",
    "### created that bins people into white/black/hispanic/other that you could use, but isnt what we previously did so...\n",
    "### some consistency is necessary I guess..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac78a319",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Combine with Discrimination Data ##\n",
    "# Here, we cleaned the Final Dataset to remove people of non-white/black and multiracial identity outside of Python. We will now read in the discrimination scores from\n",
    "# Year 2 and merge with the dataset. We're also going to add in the FreeSurfer QC as well\n",
    "os.chdir('/[Path]/ABCD_Data')\n",
    "ABCD_Dis=pd.read_csv(\"abcd_ydmes01.txt\", sep=\"\\t\", skiprows=[1])\n",
    "ABCD_DisYear2 = ABCD_Dis.loc[ABCD_Dis['eventname'] == '2_year_follow_up_y_arm_1']\n",
    "ABCD_DisYear2MergeData = ABCD_DisYear2[['subjectkey', 'dim_yesno_q1', 'dim_matrix_q1', 'dim_matrix_q2', 'dim_matrix_q3', 'dim_matrix_q4', 'dim_matrix_q5', 'dim_matrix_q6', 'dim_matrix_q7']]\n",
    "ABCD_T1QC = pd.read_csv(\"mriqcrp10301.txt\", sep=\"\\t\", skiprows=[1])\n",
    "ABCD_T1QCYear2 = ABCD_T1QC.loc[ABCD_T1QC['eventname'] == '2_year_follow_up_y_arm_1']\n",
    "ABCD_T1QCYear2MergeData = ABCD_T1QCYear2[['subjectkey', 'iqc_t1_1_qc_score']]\n",
    "os.chdir(WorkingDir)\n",
    "\n",
    "Rdata = pd.read_csv(\"BLR_Model_Data_2ndWave_02_23_24_Redux_forRandSPSS.csv\")\n",
    "NewRdata = Rdata.merge(ABCD_DisYear2MergeData, on='subjectkey', how='left')\n",
    "New2Rdata = NewRdata.merge(ABCD_T1QCYear2MergeData, on='subjectkey', how='left')\n",
    "New3Rdata = New2Rdata.merge(Z_Data, on='subjectkey', how='left')\n",
    "\n",
    "New3Rdata.to_csv('BLR_Transfer_FinalDataset_withDisQC_02_23_24_Redux_forRandSPSS.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0db4c7b-e72e-4ba9-bcee-79761087b47f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a643cb33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
